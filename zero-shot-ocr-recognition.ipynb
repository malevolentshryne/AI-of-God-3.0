{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":86284,"databundleVersionId":9813435,"sourceType":"competition"},{"sourceId":9606911,"sourceType":"datasetVersion","datasetId":5861555},{"sourceId":9606935,"sourceType":"datasetVersion","datasetId":5861572}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"text-align: center;\"><strong>Zero-shot-OCR</strong> :</h1>\n\n## (OCR) system that can recognize and extract text from images without requiring prior training on specific fonts, styles, or contexts .\n\n![](http://imgur.com/CdE5O84.gif)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(60, 121, 245) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 1. Importing Some Libraries / Dependencies </b></div>","metadata":{}},{"cell_type":"code","source":"!pip install verovio\n!pip install tiktoken","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-12T12:30:42.252726Z","iopub.execute_input":"2024-10-12T12:30:42.253111Z","iopub.status.idle":"2024-10-12T12:31:09.049832Z","shell.execute_reply.started":"2024-10-12T12:30:42.253072Z","shell.execute_reply":"2024-10-12T12:31:09.048696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom transformers import AutoModel, AutoTokenizer\nimport matplotlib.pyplot as plt\nimport re","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-12T12:31:27.589501Z","iopub.execute_input":"2024-10-12T12:31:27.589794Z","iopub.status.idle":"2024-10-12T12:31:27.594568Z","shell.execute_reply.started":"2024-10-12T12:31:27.589762Z","shell.execute_reply":"2024-10-12T12:31:27.593623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(255, 217, 19) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 2. Initializing the Tokenizer and Model </b></div>","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"text-align: center;\"><strong>General OCR Theory</strong> :</h1>\n\n## Towards OCR-2.0 via a Unified End-to-end Model by stepfun-ai\n![jzE1yg9.png](https://imgur.com/jzE1yg9.png)","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"text-align: center;\"><strong>MODEL ARCHITECTURE</strong> :</h1>\n\n![dWJtgvA.png](https://imgur.com/dWJtgvA.png)","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('ucaslcl/GOT-OCR2_0', \n                                          trust_remote_code=True)\n\nmodel = AutoModel.from_pretrained('ucaslcl/GOT-OCR2_0', \n                                  trust_remote_code=True, \n                                  low_cpu_mem_usage=True, \n                                  device_map='cuda', \n                                  use_safetensors=True, \n                                  pad_token_id=tokenizer.eos_token_id)\n\nmodel = model.eval().cuda()","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:31:33.339839Z","iopub.execute_input":"2024-10-12T12:31:33.340277Z","iopub.status.idle":"2024-10-12T12:31:37.172405Z","shell.execute_reply.started":"2024-10-12T12:31:33.340232Z","shell.execute_reply":"2024-10-12T12:31:37.171405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(31, 193, 27) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 3. Loading Files </b></div>","metadata":{}},{"cell_type":"code","source":"base_dir = '/kaggle/input/ai-of-god-3/Public_data/test_images'","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:40:30.974570Z","iopub.execute_input":"2024-10-12T12:40:30.975320Z","iopub.status.idle":"2024-10-12T12:40:30.979578Z","shell.execute_reply.started":"2024-10-12T12:40:30.975278Z","shell.execute_reply":"2024-10-12T12:40:30.978557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_excel(\"/kaggle/input/ai-of-god-3/Public_data/submission.csv.xlsx\")","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:40:32.590430Z","iopub.execute_input":"2024-10-12T12:40:32.591323Z","iopub.status.idle":"2024-10-12T12:40:32.629334Z","shell.execute_reply.started":"2024-10-12T12:40:32.591281Z","shell.execute_reply":"2024-10-12T12:40:32.628416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(255, 156, 85) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 4. A List to Store Submission Data </b></div>","metadata":{}},{"cell_type":"code","source":"submission_data = []","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:40:34.757109Z","iopub.execute_input":"2024-10-12T12:40:34.758033Z","iopub.status.idle":"2024-10-12T12:40:34.761966Z","shell.execute_reply.started":"2024-10-12T12:40:34.757996Z","shell.execute_reply":"2024-10-12T12:40:34.760970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(82, 15, 70) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 5. A Function to apply OCR to a given image </b></div>","metadata":{}},{"cell_type":"code","source":"def apply_ocr(image_path):\n    res = model.chat(tokenizer, image_path, ocr_type='ocr')\n    return res\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:40:37.296318Z","iopub.execute_input":"2024-10-12T12:40:37.296732Z","iopub.status.idle":"2024-10-12T12:40:37.301747Z","shell.execute_reply.started":"2024-10-12T12:40:37.296687Z","shell.execute_reply":"2024-10-12T12:40:37.300693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(200, 13, 12) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 6. A Function to sort image files based on numeric value in the name </b></div>","metadata":{}},{"cell_type":"code","source":"def natural_sort_key(s):\n    return [int(text) if text.isdigit() else text for text in re.split(r'(\\d+)', s)]","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:40:39.055614Z","iopub.execute_input":"2024-10-12T12:40:39.056414Z","iopub.status.idle":"2024-10-12T12:40:39.061436Z","shell.execute_reply.started":"2024-10-12T12:40:39.056372Z","shell.execute_reply":"2024-10-12T12:40:39.060261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n<div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(69, 13, 12) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px; color:rgb(34, 34, 34);\">\n    <b>7. PREDICTING TEXTS FROM THE TEST IMAGES</b>\n</div>\n\n1. **Looping Through Folders:** The code iterates over each folder in the main directory (`base_dir`), sorting them for orderly processing.\n\n2. **Identifying Page Number:** It extracts the page number from each folder name (e.g., 'Page_1' becomes '1').\n\n3. **Checking for Directories:** It verifies if the current item is indeed a folder.\n\n4. **Looping Through Images:** Inside each folder, the code loops through all PNG images, sorting them by line number using natural sorting (Because the images in our `test_images` folder are not stored in sequential order).\n\n5. **Extracting Line Number:** It retrieves the line number from the image filename (like 'L_1.png', L_2.png). \n\n6. **Formating Image ID:** The code formats each image ID as `P_{page number}_L_{line number}` (Example: `P_1_L_1`).\n\n7. **Applying OCR:** It applies OCR to extract texts from the images.\n\n8. **Storeing Results:** The formatted image ID and predicted texts are saved in a list (4.) called `submission_data`.\n\n9. **Displaying Images:** For verifying it will displays the first few images along with their predicted text .\n\n","metadata":{}},{"cell_type":"code","source":"!pip install language-tool-python\n\nimport language_tool_python\n\n# Initialize the tool for Spanish\ntool = language_tool_python.LanguageTool('es')","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:37:43.206357Z","iopub.execute_input":"2024-10-12T12:37:43.207153Z","iopub.status.idle":"2024-10-12T12:38:06.377895Z","shell.execute_reply.started":"2024-10-12T12:37:43.207113Z","shell.execute_reply":"2024-10-12T12:38:06.376657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for folder in sorted(os.listdir(base_dir)):\n    folder_path = os.path.join(base_dir, folder)\n    page_number = folder.split('_')[-1]\n    \n    if os.path.isdir(folder_path):\n        for image_file in sorted(os.listdir(folder_path), key=natural_sort_key):\n            if image_file.endswith('.png'):  \n                image_path = os.path.join(folder_path, image_file)\n                line_number = image_file.split('_')[-1].split('.')[0]\n                formatted_image_id = f'P_{page_number}_L_{line_number}'\n                predicted_text = apply_ocr(image_path)\n\n                # Incorrect Spanish sentence\n                incorrect_text = predicted_text\n                \n                # Check and correct the sentence\n                matches = tool.check(incorrect_text)\n                predicted_text = language_tool_python.utils.correct(incorrect_text, matches)\n                                \n                submission_data.append({'unique id': formatted_image_id, 'prediction': predicted_text})\n                \n                print(f\"Processed {formatted_image_id}: {predicted_text}\")\n                if len(submission_data) < 10:   #-------> First 10 predicted Images\n                    img = plt.imread(image_path)\n                    plt.imshow(img)\n                    plt.axis('off')\n                    plt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-12T12:40:47.044857Z","iopub.execute_input":"2024-10-12T12:40:47.045266Z","iopub.status.idle":"2024-10-12T12:43:22.414142Z","shell.execute_reply.started":"2024-10-12T12:40:47.045227Z","shell.execute_reply":"2024-10-12T12:43:22.412969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"8\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(20, 13, 121) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 8. Creating a Submission file </b></div>","metadata":{}},{"cell_type":"code","source":"for index, row in submission_df.iterrows():\n    matching_prediction = next((pred for pred in submission_data if pred['unique id'] == row['unique id']), None)\n    if matching_prediction:\n        submission_df.at[index, 'prediction'] = matching_prediction['prediction']  \n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:43:43.443449Z","iopub.execute_input":"2024-10-12T12:43:43.444391Z","iopub.status.idle":"2024-10-12T12:43:43.530645Z","shell.execute_reply.started":"2024-10-12T12:43:43.444348Z","shell.execute_reply":"2024-10-12T12:43:43.529812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.rename(columns={'unique id': 'unique Id'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:55:22.385617Z","iopub.execute_input":"2024-10-12T12:55:22.386556Z","iopub.status.idle":"2024-10-12T12:55:22.391741Z","shell.execute_reply.started":"2024-10-12T12:55:22.386513Z","shell.execute_reply":"2024-10-12T12:55:22.390714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)\n\nprint(\"submission file created successfully!\")","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:55:26.276209Z","iopub.execute_input":"2024-10-12T12:55:26.276715Z","iopub.status.idle":"2024-10-12T12:55:26.284499Z","shell.execute_reply.started":"2024-10-12T12:55:26.276675Z","shell.execute_reply":"2024-10-12T12:55:26.283558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:55:29.987080Z","iopub.execute_input":"2024-10-12T12:55:29.987456Z","iopub.status.idle":"2024-10-12T12:55:29.997978Z","shell.execute_reply.started":"2024-10-12T12:55:29.987421Z","shell.execute_reply":"2024-10-12T12:55:29.997003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"box-shadow: rgba(240, 46, 170, 0.4) -5px 5px inset, rgba(240, 46, 170, 0.3) -10px 10px inset, rgba(240, 46, 170, 0.2) -15px 15px inset, rgba(240, 46, 170, 0.1) -20px 20px inset, rgba(240, 46, 170, 0.05) -25px 25px inset; padding:20px; font-size:30px; font-family: consolas; display:fill; border-radius:15px; color: rgba(240, 46, 170, 0.7)\"> <b> 💻 Thank You!</b></div>\n\n<p style=\"font-family:verdana; color:rgb(34, 34, 34); font-family: consolas; font-size: 16px;\"> If you enjoy this zero-shot OCR,upvote this notebook. Happy coding!🚀💻🌟. <br>\n    </p>","metadata":{}}]}